:Namespace Loss
    l2←1                                               ⍝ standard squared-residual
    L2←{(×⍨⍺×⍵)⍺}
    
    huber←1.345                                        ⍝ ~95% efficiency for normal errors
    Huber←{y←⍺>|⍵ ⋄ Y←y⍨ ⋄ N←~Y                        ⍝ L2 for small residuals, lineal for large ones
        (((⍺÷2)-⍨⍺×|)@N×⍨@Y ⍵)((⍺÷⍨|)@N 1@Y ⍵)
    }
    cauchy←2.385                                       ⍝ ~95% efficiency for normal errors
    Cauchy←{(⍺×(⍺÷2)×⍟1+r)(÷1+r←×⍨⍵÷⍺)}                ⍝ strongly downweights large outliers
    
    softl1←1
    SoftL1←{(⍺×⍺×r-1)(÷r←(1+×⍨⍵÷⍺)*÷2)}                ⍝ L2 for small residuals, L1 for large ones
    
    tukey←4.685                                        ⍝ ~95% efficiency for normal errors
    Tukey←{k←(×⍨⍺)÷6 ⋄ y←⍺>|⍵ ⋄ Y←y⍨ ⋄ N←~Y            ⍝ re-descending M-estimator
        (k@Y(k×1-3*⍨1-⊢)@N⊢r)(0@Y(×⍨1-⊢)@N⊢r←×⍨⍵÷⍺)
    }
    welsh←2.985                                        ⍝ ~95% efficiency for normal errors
    Welsh←{(⍺×(⍺÷2)×1-e)(e←*-×⍨⍵÷⍺)}                   ⍝ smoother re-descending M-estimator
    
    fair←1
    Fair←{(⍺×⍺×r-⍟1+r)(÷1+r←(|⍵)÷⍺)}                   ⍝ no re-descending
    
    arctan←1
    Arctan←{(⍺×(⍺÷2)×¯3○r)(÷1+×⍨r←×⍨⍵÷⍺)}              ⍝ limits maximum loss
:EndNamespace
